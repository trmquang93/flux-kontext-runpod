#!/usr/bin/env python3
"""
Enhanced RunPod serverless handler for FLUX.1 Kontext-dev image editing.
Based on proven production patterns for reliability and performance.
All dependencies embedded to avoid import issues.
"""

import runpod
import sys
import os
import time
import logging
import traceback
import base64
import io
import uuid
import json
import binascii
import concurrent.futures
from typing import Optional

# Set up logging with comprehensive format
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# CUDA ê²€ì‚¬ ë° ì„¤ì • (Enhanced pattern)
def check_cuda_availability():
    """CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    try:
        import torch
        if torch.cuda.is_available():
            logger.info("âœ… CUDA is available and working")
            os.environ['CUDA_VISIBLE_DEVICES'] = '0'
            return True
        else:
            logger.error("âŒ CUDA is not available")
            raise RuntimeError("CUDA is required but not available")
    except Exception as e:
        logger.error(f"âŒ CUDA check failed: {e}")
        raise RuntimeError(f"CUDA initialization failed: {e}")

# CUDA ê²€ì‚¬ ì‹¤í–‰
try:
    cuda_available = check_cuda_availability()
    if not cuda_available:
        raise RuntimeError("CUDA is not available")
except Exception as e:
    logger.error(f"Failed to initialize CUDA: {e}")
    sys.exit(1)

# Import ML dependencies after CUDA check
try:
    import torch
    from PIL import Image
    import numpy as np
    from models.flux_kontext import FluxKontextManager
    from models.image_processor import ImageProcessor
    
    logger.info("âœ… All ML dependencies loaded successfully")
except ImportError as e:
    logger.error(f"âŒ Failed to import ML dependencies: {e}")
    raise RuntimeError(f"Missing dependencies: {e}")

# Global model manager (Enhanced pattern)
flux_manager = None
image_processor = None

def initialize_models():
    """ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global flux_manager, image_processor
    
    if flux_manager is not None:
        logger.info("âœ… Models already initialized")
        return True
        
    try:
        logger.info("ğŸ”„ Initializing FLUX.1 Kontext models...")
        
        # Initialize image processor
        image_processor = ImageProcessor()
        logger.info("âœ… Image processor initialized")
        
        # Initialize FLUX model manager
        flux_manager = FluxKontextManager()
        
        # Use asyncio to run async initialization in sync context
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(flux_manager.initialize())
        loop.close()
        
        logger.info("âœ… FLUX.1 Kontext model initialized successfully")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Model initialization failed: {e}")
        logger.error(traceback.format_exc())
        raise RuntimeError(f"Model initialization failed: {e}")

# Enhanced input validation
def validate_input_data(job_input):
    """ì…ë ¥ ë°ì´í„°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not isinstance(job_input, dict):
        raise ValueError("Input must be a dictionary")
    
    # Required fields
    if 'task_type' not in job_input:
        raise ValueError("Missing required field: task_type")
    
    task_type = job_input['task_type']
    
    if task_type == 'health':
        return True
    elif task_type == 'debug':
        return True
    elif task_type in ['edit', 'generate']:
        if 'prompt' not in job_input:
            raise ValueError(f"Task {task_type} requires 'prompt' field")
        if 'image_data' not in job_input:
            raise ValueError(f"Task {task_type} requires 'image_data' field")
        
        # Validate image data
        image_data = job_input['image_data']
        if not isinstance(image_data, str) or len(image_data) == 0:
            raise ValueError("image_data must be a non-empty string")
        
        # Check if it's base64 encoded
        try:
            if image_data.startswith('data:image/'):
                # Remove data URL prefix
                image_data = image_data.split(',', 1)[1]
            base64.b64decode(image_data)
        except Exception:
            raise ValueError("image_data must be valid base64 encoded image")
            
        return True
    else:
        raise ValueError(f"Unknown task_type: {task_type}")

# Enhanced image processing with better error handling
def process_image_with_flux(image_data, prompt, guidance_scale=2.5, num_inference_steps=50):
    """FLUX.1 Kontextë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        logger.info(f"ğŸ”„ Processing image with FLUX.1 Kontext: '{prompt[:50]}...'")
        
        # Decode base64 image
        if image_data.startswith('data:image/'):
            image_data = image_data.split(',', 1)[1]
        
        image_bytes = base64.b64decode(image_data)
        input_image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        
        logger.info(f"ğŸ“ Input image size: {input_image.size}")
        
        # Process with FLUX.1 Kontext
        processed_image = flux_manager.edit_image(
            image=input_image,
            prompt=prompt,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps
        )
        
        # Convert result to base64
        buffer = io.BytesIO()
        processed_image.save(buffer, format='JPEG', quality=95)
        result_base64 = base64.b64encode(buffer.getvalue()).decode()
        
        logger.info(f"âœ… FLUX processing completed. Result size: {len(result_base64)} chars")
        
        return {
            'image': result_base64,
            'format': 'jpeg',
            'size': processed_image.size,
            'processing_info': {
                'model': 'FLUX.1-Kontext-dev',
                'guidance_scale': guidance_scale,
                'num_inference_steps': num_inference_steps,
                'prompt_length': len(prompt)
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ FLUX processing failed: {e}")
        logger.error(traceback.format_exc())
        raise RuntimeError(f"Image processing failed: {e}")

# Main handler function
def handler(job):
    """RunPod ì„œë²„ë¦¬ìŠ¤ í•¸ë“¤ëŸ¬ ë©”ì¸ í•¨ìˆ˜"""
    job_id = job.get('id', 'unknown')
    
    try:
        logger.info(f"ğŸš€ Processing job {job_id}")
        
        # Get job input
        job_input = job.get('input', {})
        logger.info(f"ğŸ“ Job input keys: {list(job_input.keys())}")
        
        # Validate input
        validate_input_data(job_input)
        
        task_type = job_input['task_type']
        logger.info(f"ğŸ“‹ Task type: {task_type}")
        
        # Handle different task types
        if task_type == 'health':
            return {
                'status': 'healthy',
                'model': 'FLUX.1-Kontext-dev',
                'cuda_available': torch.cuda.is_available(),
                'gpu_memory': torch.cuda.get_device_properties(0).total_memory if torch.cuda.is_available() else 0,
                'timestamp': time.time()
            }
            
        elif task_type == 'debug':
            return {
                'status': 'debug',
                'job_id': job_id,
                'input_keys': list(job_input.keys()),
                'cuda_info': {
                    'available': torch.cuda.is_available(),
                    'device_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,
                    'current_device': torch.cuda.current_device() if torch.cuda.is_available() else None
                },
                'model_status': 'initialized' if flux_manager else 'not_initialized',
                'timestamp': time.time()
            }
            
        elif task_type in ['edit', 'generate']:
            # Initialize models if not already done
            if flux_manager is None:
                logger.info("ğŸ”„ Models not initialized, initializing now...")
                initialize_models()
            
            # Process image
            result = process_image_with_flux(
                image_data=job_input['image_data'],
                prompt=job_input['prompt'],
                guidance_scale=job_input.get('guidance_scale', 2.5),
                num_inference_steps=job_input.get('num_inference_steps', 50)
            )
            
            logger.info(f"âœ… Job {job_id} completed successfully")
            return result
            
        else:
            raise ValueError(f"Unknown task type: {task_type}")
            
    except Exception as e:
        logger.error(f"âŒ Job {job_id} failed: {e}")
        logger.error(traceback.format_exc())
        
        return {
            'error': str(e),
            'job_id': job_id,
            'timestamp': time.time(),
            'error_type': type(e).__name__
        }

# RunPod ì„œë²„ë¦¬ìŠ¤ ì‹œì‘
if __name__ == "__main__":
    logger.info("ğŸš€ Starting FLUX.1 Kontext RunPod serverless handler...")
    
    try:
        # Pre-initialize models for better performance
        logger.info("ğŸ”„ Pre-initializing models...")
        initialize_models()
        logger.info("âœ… Pre-initialization complete")
        
        # Start RunPod serverless
        runpod.serverless.start({"handler": handler})
        
    except Exception as e:
        logger.error(f"âŒ Failed to start handler: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)