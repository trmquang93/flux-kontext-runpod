#!/usr/bin/env python3
"""
Deployment script for FLUX.1 Kontext-dev server to RunPod.
This deploys the real AI implementation with proper FLUX.1 Kontext models.
"""

import argparse
import subprocess
import sys
import time
import logging

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def run_command(cmd, cwd=None, check=True):
    """Run a shell command and return the result."""
    logger.info(f"Running: {cmd}")
    try:
        result = subprocess.run(
            cmd, shell=True, cwd=cwd, check=check,
            capture_output=True, text=True
        )
        if result.stdout:
            logger.info(f"Output: {result.stdout.strip()}")
        return result
    except subprocess.CalledProcessError as e:
        logger.error(f"Command failed: {e}")
        if e.stderr:
            logger.error(f"Error: {e.stderr.strip()}")
        raise


def build_docker_image(image_name, tag="latest"):
    """Build the Docker image."""
    logger.info("üî® Building Docker image with FLUX.1 Kontext-dev support...")
    
    try:
        # Build the image
        cmd = f"docker build -t {image_name}:{tag} ."
        run_command(cmd)
        
        logger.info(f"‚úÖ Docker image built successfully: {image_name}:{tag}")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Docker build failed: {e}")
        return False


def push_docker_image(image_name, tag="latest", registry="docker.io"):
    """Push the Docker image to registry."""
    logger.info(f"üì§ Pushing Docker image to {registry}...")
    
    try:
        full_image_name = f"{registry}/{image_name}:{tag}"
        
        # Tag the image for the registry
        tag_cmd = f"docker tag {image_name}:{tag} {full_image_name}"
        run_command(tag_cmd)
        
        # Push the image
        push_cmd = f"docker push {full_image_name}"
        run_command(push_cmd)
        
        logger.info(f"‚úÖ Image pushed successfully: {full_image_name}")
        return full_image_name
        
    except Exception as e:
        logger.error(f"‚ùå Docker push failed: {e}")
        return None


def deploy_to_runpod(
    image_name,
    endpoint_name="flux-kontext-dev",
    gpu_type="NVIDIA RTX A5000",
    min_workers=0,
    max_workers=3,
    idle_timeout=5,
    registry="docker.io"
):
    """Deploy the image to RunPod serverless."""
    logger.info("üöÄ Deploying FLUX.1 Kontext-dev to RunPod serverless...")
    
    full_image_name = f"{registry}/{image_name}:latest"
    
    try:
        # Create the deployment configuration
        deployment_config = {
            "name": endpoint_name,
            "image": full_image_name,
            "gpu_types": [gpu_type],
            "min_workers": min_workers,
            "max_workers": max_workers,
            "idle_timeout": idle_timeout,
            "container_disk_in_gb": 50,  # Increased for FLUX.1 Kontext models
            "volume_in_gb": 100,  # Network volume for model caching
            "volume_mount_path": "/runpod-volume",
            "env": {
                "SERVER_MODE": "runpod",
                "CUDA_VISIBLE_DEVICES": "0",
                "HF_HUB_ENABLE_HF_TRANSFER": "1",
                "TORCH_HOME": "/runpod-volume/.torch",
                "HF_HOME": "/runpod-volume/.huggingface",
                "TRANSFORMERS_CACHE": "/runpod-volume/.transformers"
            }
        }
        
        logger.info("üìã Deployment Configuration:")
        logger.info(f"  Name: {endpoint_name}")
        logger.info(f"  Image: {full_image_name}")
        logger.info(f"  GPU: {gpu_type}")
        logger.info(f"  Workers: {min_workers}-{max_workers}")
        logger.info(f"  Idle Timeout: {idle_timeout}s")
        logger.info(f"  Container Disk: 50GB")
        logger.info(f"  Network Volume: 100GB")
        
        # Note: This would typically use RunPod's API or CLI
        logger.info("‚ÑπÔ∏è Use the following configuration in RunPod console:")
        logger.info("=" * 50)
        logger.info(f"Endpoint Name: {endpoint_name}")
        logger.info(f"Docker Image: {full_image_name}")
        logger.info(f"GPU Type: {gpu_type}")
        logger.info(f"Min Workers: {min_workers}")
        logger.info(f"Max Workers: {max_workers}")
        logger.info(f"Idle Timeout: {idle_timeout}s")
        logger.info(f"Container Disk: 50GB")
        logger.info(f"Network Volume: 100GB at /runpod-volume")
        logger.info("Environment Variables:")
        for key, value in deployment_config["env"].items():
            logger.info(f"  {key}={value}")
        logger.info("=" * 50)
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå RunPod deployment failed: {e}")
        return False


def test_local_container(image_name, tag="latest"):
    """Test the Docker container locally."""
    logger.info("üß™ Testing Docker container locally...")
    
    try:
        # Run a basic health check
        cmd = f"docker run --rm --gpus all {image_name}:{tag} python3 -c \"import runpod_handler; print('‚úÖ Container test passed')\""
        result = run_command(cmd, check=False)
        
        if result.returncode == 0:
            logger.info("‚úÖ Local container test passed")
            return True
        else:
            logger.warning("‚ö†Ô∏è Local container test had issues but may still work in RunPod environment")
            return True  # Continue anyway as local GPU setup might differ
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Local test failed: {e}")
        logger.info("This may be normal if local GPU setup differs from RunPod")
        return True


def main():
    parser = argparse.ArgumentParser(description="Deploy FLUX.1 Kontext-dev server to RunPod")
    parser.add_argument("--image-name", default="artyx-flux-kontext-server", 
                       help="Docker image name")
    parser.add_argument("--registry", default="docker.io", 
                       help="Docker registry (default: docker.io)")
    parser.add_argument("--endpoint-name", default="flux-kontext-dev", 
                       help="RunPod endpoint name")
    parser.add_argument("--gpu-type", default="NVIDIA RTX A5000", 
                       help="GPU type for RunPod")
    parser.add_argument("--max-workers", type=int, default=3, 
                       help="Maximum number of workers")
    parser.add_argument("--skip-build", action="store_true", 
                       help="Skip Docker build step")
    parser.add_argument("--skip-push", action="store_true", 
                       help="Skip Docker push step")
    parser.add_argument("--skip-test", action="store_true", 
                       help="Skip local container test")
    
    args = parser.parse_args()
    
    logger.info("üöÄ Starting FLUX.1 Kontext-dev deployment process...")
    logger.info(f"Image: {args.registry}/{args.image_name}")
    logger.info(f"Endpoint: {args.endpoint_name}")
    logger.info(f"GPU Type: {args.gpu_type}")
    
    success = True
    
    # Step 1: Build Docker image
    if not args.skip_build:
        if not build_docker_image(args.image_name):
            logger.error("‚ùå Build failed")
            success = False
    else:
        logger.info("‚è≠Ô∏è Skipping Docker build")
    
    # Step 2: Test container locally
    if success and not args.skip_test:
        if not test_local_container(args.image_name):
            logger.warning("‚ö†Ô∏è Local test had issues")
    elif args.skip_test:
        logger.info("‚è≠Ô∏è Skipping local test")
    
    # Step 3: Push to registry
    if success and not args.skip_push:
        pushed_image = push_docker_image(args.image_name, registry=args.registry)
        if not pushed_image:
            logger.error("‚ùå Push failed")
            success = False
    else:
        logger.info("‚è≠Ô∏è Skipping Docker push")
    
    # Step 4: Deploy to RunPod
    if success:
        if deploy_to_runpod(
            args.image_name,
            endpoint_name=args.endpoint_name,
            gpu_type=args.gpu_type,
            max_workers=args.max_workers,
            registry=args.registry
        ):
            logger.info("‚úÖ Deployment process completed successfully!")
            logger.info("üîó Next steps:")
            logger.info("1. Go to RunPod console: https://www.runpod.io/serverless")
            logger.info("2. Create new serverless endpoint with the configuration above")
            logger.info("3. Wait for model download and initialization")
            logger.info("4. Test with a health check request")
        else:
            logger.error("‚ùå RunPod deployment configuration failed")
            success = False
    
    if success:
        logger.info("üéâ FLUX.1 Kontext-dev deployment ready!")
    else:
        logger.error("‚ùå Deployment process failed")
        sys.exit(1)


if __name__ == "__main__":
    main()